# ![Version](https://img.shields.io/badge/version-1.0.0-blue.svg) 

# ğŸ”—ğŸ¬ Predicting the Unseen: Multi-modal LLMs with Memory Consolidation for Video Future Event Prediction

## ğŸ” Overview 
 <table>
    <tr>
        <td>This paper proposes a multi-modal large language model for video future event prediction termed MC-VFEP, which leverages a memory consolidation mechanism encompassing visual knowledge memory consolidation and scene graph knowledge reasoning modules.</td>
    </tr>
</table>

 ![contents](https://github.com/keyancaigou/MC-VFEP/blob/main/model.png)

## ğŸ“ Code
 Code will be made public soon

## ğŸ“ Data
Data will be made public soon

### License
The code is released under Apache License 2.0 for Noncommercial use only.
